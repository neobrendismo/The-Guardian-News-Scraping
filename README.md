# **News Content Collect and Store**

The objective of this project is to develop a solution that crawls news articles from [The Guardian website](https://www.theguardian.com/au), processes the content, and stores it in Google BigQuery. The project utilizes the [Scrapy](https://scrapy.org/) framework to efficiently scrape and cleanse the data before integration into BigQuery.

# **Requirements**
    Python
    Scrapy
    readability
    pandas
    google-cloud-bigquery
    google-auth

# **Methodology**
1. we need to create a free account in GCP: https://cloud.google.com/free
